{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Fine-tune SpeechT5 TTS Model for Haitian Creole\n",
    "\n",
    "This notebook fine-tunes a SpeechT5 Text-to-Speech model for Haitian Creole using the EdManZoeTech/edman_haitian_creole_dataset_4_tts dataset.\n",
    "\n",
    "## Features:\n",
    "- Dataset loading and preprocessing\n",
    "- Audio resampling and normalization\n",
    "- X-vector extraction for speaker characteristics\n",
    "- Model fine-tuning with Hugging Face Trainer\n",
    "- Inference and testing capabilities\n",
    "- Mixed precision training and logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "# Install required packages\n",
    "%pip install torch torchaudio\n",
    "%pip install transformers datasets\n",
    "%pip install librosa soundfile\n",
    "%pip install scikit-learn\n",
    "%pip install huggingface_hub tensorboard\n",
    "%pip install torchcodec\n",
    "\n",
    "# Restart runtime to ensure torchcodec is properly loaded\n",
    "import os\n",
    "os.kill(os.getpid(), 9)\n",
    "\n",
    "# For Colab GPU support\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5f9aa8b7fa4496aa722a429d4faaf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully authenticated with Hugging Face Hub\n"
     ]
    }
   ],
   "source": [
    "# Authenticate with Hugging Face Hub (run this first)\n",
    "from huggingface_hub import login\n",
    "try:\n",
    "    login()\n",
    "    print(\"✅ Successfully authenticated with Hugging Face Hub\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ HF Hub authentication failed: {e}\")\n",
    "    print(\"Please run 'huggingface-cli login' in terminal or provide HF token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "install"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ep2/anaconda3/lib/python3.13/site-packages (2.7.1)\n",
      "Requirement already satisfied: torchaudio in /home/ep2/anaconda3/lib/python3.13/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /home/ep2/anaconda3/lib/python3.13/site-packages (4.54.0)\n",
      "Requirement already satisfied: datasets in /home/ep2/anaconda3/lib/python3.13/site-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /home/ep2/anaconda3/lib/python3.13/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from transformers) (0.34.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ep2/anaconda3/lib/python3.13/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ep2/anaconda3/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ep2/anaconda3/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ep2/anaconda3/lib/python3.13/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ep2/anaconda3/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ep2/anaconda3/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ep2/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ep2/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ep2/anaconda3/lib/python3.13/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home/ep2/anaconda3/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ep2/anaconda3/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ep2/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ep2/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.18.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ep2/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ep2/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ep2/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ep2/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ep2/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: librosa in /home/ep2/anaconda3/lib/python3.13/site-packages (0.11.0)\n",
      "Requirement already satisfied: soundfile in /home/ep2/anaconda3/lib/python3.13/site-packages (0.13.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/ep2/anaconda3/lib/python3.13/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from librosa) (0.61.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /home/ep2/anaconda3/lib/python3.13/site-packages (from librosa) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from librosa) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/ep2/anaconda3/lib/python3.13/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: standard-aifc in /home/ep2/anaconda3/lib/python3.13/site-packages (from librosa) (3.13.0)\n",
      "Requirement already satisfied: standard-sunau in /home/ep2/anaconda3/lib/python3.13/site-packages (from librosa) (3.13.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/ep2/anaconda3/lib/python3.13/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: packaging in /home/ep2/anaconda3/lib/python3.13/site-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ep2/anaconda3/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ep2/anaconda3/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ep2/anaconda3/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from scikit-learn>=1.1.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: standard-chunk in /home/ep2/anaconda3/lib/python3.13/site-packages (from standard-aifc->librosa) (3.13.0)\n",
      "Requirement already satisfied: audioop-lts in /home/ep2/anaconda3/lib/python3.13/site-packages (from standard-aifc->librosa) (0.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /home/ep2/anaconda3/lib/python3.13/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/ep2/anaconda3/lib/python3.13/site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: huggingface_hub in /home/ep2/anaconda3/lib/python3.13/site-packages (0.34.0)\n",
      "Requirement already satisfied: tensorboard in /home/ep2/anaconda3/lib/python3.13/site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in /home/ep2/anaconda3/lib/python3.13/site-packages (from huggingface_hub) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ep2/anaconda3/lib/python3.13/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/ep2/anaconda3/lib/python3.13/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ep2/anaconda3/lib/python3.13/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ep2/anaconda3/lib/python3.13/site-packages (from huggingface_hub) (1.1.5)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ep2/anaconda3/lib/python3.13/site-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/ep2/anaconda3/lib/python3.13/site-packages (from tensorboard) (1.74.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ep2/anaconda3/lib/python3.13/site-packages (from tensorboard) (3.8)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from tensorboard) (2.1.3)\n",
      "Requirement already satisfied: pillow in /home/ep2/anaconda3/lib/python3.13/site-packages (from tensorboard) (11.1.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/ep2/anaconda3/lib/python3.13/site-packages (from tensorboard) (5.29.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from tensorboard) (72.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ep2/anaconda3/lib/python3.13/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ep2/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ep2/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ep2/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ep2/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install torch torchaudio\n",
    "%pip install transformers datasets\n",
    "%pip install librosa soundfile\n",
    "%pip install scikit-learn\n",
    "%pip install huggingface_hub tensorboard\n",
    "\n",
    "# For Colab GPU support\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports_code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "\n",
    "# Hugging Face imports\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict, load_dataset, Audio\n",
    "from transformers import (\n",
    "    SpeechT5Processor,\n",
    "    SpeechT5ForTextToSpeech,\n",
    "    SpeechT5HifiGan,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from transformers.models.speecht5 import SpeechT5FeatureExtractor\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Optional imports for enhanced features\n",
    "try:\n",
    "    from huggingface_hub import HfApi, login, create_repo\n",
    "    HF_HUB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    HF_HUB_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    TENSORBOARD_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TENSORBOARD_AVAILABLE = False\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"All dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "constants"
   },
   "source": [
    "@dataclass\n",
    "class TTSConfig:\n",
    "    \"\"\"Configuration class for Haitian Creole TTS training\"\"\"\n",
    "    \n",
    "    # Model and dataset settings\n",
    "    model_name: str = \"microsoft/speecht5_tts\"\n",
    "    vocoder_name: str = \"microsoft/speecht5_hifigan\"\n",
    "    dataset_name: str = \"EdManZoeTech/edman_haitian_creole_dataset_4_tts\"\n",
    "    \n",
    "    # Audio settings\n",
    "    sample_rate: int = 16000\n",
    "    min_audio_length: float = 1.0  # seconds\n",
    "    max_audio_length: float = 20.0  # seconds\n",
    "    \n",
    "    # Training settings\n",
    "    output_dir: str = \"./haitian_creole_tts_model\"\n",
    "    cache_dir: str = \"./cache\"\n",
    "    num_train_epochs: int = 10\n",
    "    per_device_train_batch_size: int = 4\n",
    "    per_device_eval_batch_size: int = 4\n",
    "    learning_rate: float = 1e-5\n",
    "    weight_decay: float = 0.01\n",
    "    warmup_steps: int = 500\n",
    "    logging_steps: int = 10\n",
    "    eval_steps: int = 100\n",
    "    save_steps: int = 500\n",
    "    fp16: bool = True  # Use mixed precision training\n",
    "    dataloader_num_workers: int = 2\n",
    "    \n",
    "    # Model settings\n",
    "    max_text_length: int = 512\n",
    "    max_speech_length: int = 2048\n",
    "\n",
    "# Constants\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SAMPLE_RATE = 16000\n",
    "XVECTOR_DIM = 512  # Dimension for X-vector embeddings\n",
    "\n",
    "# Initialize configuration\n",
    "config = TTSConfig()\n",
    "\n",
    "print(f\"Configuration initialized!\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Model: {config.model_name}\")\n",
    "print(f\"Dataset: {config.dataset_name}\")\n",
    "print(f\"Output directory: {config.output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "constants_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HaitianCreoleTTSTrainer class defined!\n"
     ]
    }
   ],
   "source": [
    "class HaitianCreoleTTSTrainer:\n",
    "    \"\"\"Main class for fine-tuning SpeechT5 for Haitian Creole TTS\"\"\"\n",
    "    \n",
    "    def __init__(self, config: TTSConfig):\n",
    "        self.config = config\n",
    "        self.processor = None\n",
    "        self.model = None\n",
    "        self.vocoder = None\n",
    "        self.dataset = None\n",
    "        self.dataset_splits = None\n",
    "        \n",
    "        # Create output directories\n",
    "        Path(config.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "        Path(config.cache_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Initialize HF Hub integration\n",
    "        if HF_HUB_AVAILABLE:\n",
    "            self.hf_api = HfApi()\n",
    "            self.hf_repo_id = f\"haitian-creole-tts-{config.model_name.replace('/', '-')}\"\n",
    "            \n",
    "            try:\n",
    "                create_repo(self.hf_repo_id, exist_ok=True, private=False)\n",
    "                logger.info(f\"Initialized HF Hub repo: {self.hf_repo_id}\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not initialize HF Hub repo: {e}\")\n",
    "                self.hf_api = None\n",
    "        \n",
    "        if TENSORBOARD_AVAILABLE:\n",
    "            self.tb_writer = SummaryWriter(log_dir=f\"{config.output_dir}/tensorboard\")\n",
    "    \n",
    "    def load_dataset(self) -> None:\n",
    "        \"\"\"Load and inspect the Haitian Creole dataset\"\"\"\n",
    "        logger.info(f\"Loading dataset: {self.config.dataset_name}\")\n",
    "        \n",
    "        try:\n",
    "            # Try loading with audio decoding first\n",
    "            try:\n",
    "                from datasets import Audio\n",
    "                self.dataset = load_dataset(\n",
    "                    self.config.dataset_name, \n",
    "                    split=\"train\",\n",
    "                    features=datasets.Features({\n",
    "                        'audio': Audio(sampling_rate=16000),\n",
    "                        'text': datasets.Value('string')\n",
    "                    })\n",
    "                )\n",
    "            except ImportError:\n",
    "                # Fallback: load without automatic audio decoding\n",
    "                logger.warning(\"torchcodec not available, loading dataset without automatic audio decoding\")\n",
    "                self.dataset = load_dataset(self.config.dataset_name, split=\"train\")\n",
    "            \n",
    "            logger.info(f\"Dataset loaded successfully. Size: {len(self.dataset)}\")\n",
    "            \n",
    "            # Print dataset info and examples\n",
    "            logger.info(f\"Dataset features: {self.dataset.features}\")\n",
    "            \n",
    "            # Show first few examples\n",
    "            logger.info(\"Sample examples:\")\n",
    "            for i in range(min(3, len(self.dataset))):\n",
    "                example = self.dataset[i]\n",
    "                logger.info(f\"Example {i+1}:\")\n",
    "                logger.info(f\"  Text: {example.get('text', 'N/A')}\")\n",
    "                if \"audio\" in example:\n",
    "                    audio_info = example[\"audio\"]\n",
    "                    if isinstance(audio_info, dict):\n",
    "                        logger.info(f\"  Audio shape: {len(audio_info['array']) if 'array' in audio_info else 'N/A'}\")\n",
    "                        logger.info(f\"  Sample rate: {audio_info.get('sampling_rate', 'N/A')}\")\n",
    "                    else:\n",
    "                        logger.info(f\"  Audio type: {type(audio_info)}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading dataset: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def normalize_haitian_text(self, text: str) -> str:\n",
    "        \"\"\"Normalize Haitian Creole text for TTS\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Handle Haitian Creole specific characters\n",
    "        char_map = {\n",
    "            \"è\": \"e\", \"é\": \"e\", \"ê\": \"e\", \"ë\": \"e\",\n",
    "            \"à\": \"a\", \"á\": \"a\", \"â\": \"a\", \"ä\": \"a\",\n",
    "            \"ì\": \"i\", \"í\": \"i\", \"î\": \"i\", \"ï\": \"i\",\n",
    "            \"ò\": \"o\", \"ó\": \"o\", \"ô\": \"o\", \"ö\": \"o\",\n",
    "            \"ù\": \"u\", \"ú\": \"u\", \"û\": \"u\", \"ü\": \"u\",\n",
    "            \"ç\": \"c\", \"ñ\": \"n\",\n",
    "        }\n",
    "        \n",
    "        for old_char, new_char in char_map.items():\n",
    "            text = text.replace(old_char, new_char)\n",
    "        \n",
    "        # Remove or replace punctuation (keep basic punctuation for prosody)\n",
    "        text = re.sub(r\"[^\\w\\s\\.\\,\\!\\?\\-]\", \"\", text)\n",
    "        \n",
    "        # Clean up whitespace\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def resample_audio(self, audio_array: np.ndarray, orig_sr: int) -> np.ndarray:\n",
    "        \"\"\"Resample audio to target sample rate\"\"\"\n",
    "        if orig_sr != self.config.sample_rate:\n",
    "            audio_array = librosa.resample(\n",
    "                audio_array, orig_sr=orig_sr, target_sr=self.config.sample_rate\n",
    "            )\n",
    "        return audio_array\n",
    "\n",
    "print(\"HaitianCreoleTTSTrainer class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trainer_class"
   },
   "source": [
    "## Main Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "trainer_class_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main trainer class structure ready!\n"
     ]
    }
   ],
   "source": [
    "# The main trainer class continues from previous cells\n",
    "# Additional methods will be added in subsequent cells\n",
    "\n",
    "print(\"Main trainer class structure ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvector"
   },
   "source": [
    "## X-Vector Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "xvector_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-vector extraction method added!\n"
     ]
    }
   ],
   "source": [
    "def extract_xvector(self, audio_array: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Extract X-vector for speaker characteristics\"\"\"\n",
    "    # For this implementation, we'll create a simple speaker embedding\n",
    "    # In a production system, you'd use a proper X-vector extractor\n",
    "    \n",
    "    # Compute basic audio features as a proxy for X-vector\n",
    "    # This is a simplified approach - in practice, use a trained X-vector model\n",
    "    \n",
    "    # Compute spectral features\n",
    "    stft = librosa.stft(audio_array, n_fft=512, hop_length=256)\n",
    "    magnitude = np.abs(stft)\n",
    "    \n",
    "    # Compute statistical features across time\n",
    "    features = []\n",
    "    \n",
    "    # Mean and std of magnitude spectrum\n",
    "    features.extend([np.mean(magnitude), np.std(magnitude)])\n",
    "    \n",
    "    # Spectral centroid, rolloff, zero crossing rate\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=audio_array, sr=self.config.sample_rate)[0]\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_array, sr=self.config.sample_rate)[0]\n",
    "    zcr = librosa.feature.zero_crossing_rate(audio_array)[0]\n",
    "    \n",
    "    features.extend([\n",
    "        np.mean(spectral_centroids), np.std(spectral_centroids),\n",
    "        np.mean(spectral_rolloff), np.std(spectral_rolloff),\n",
    "        np.mean(zcr), np.std(zcr),\n",
    "    ])\n",
    "    \n",
    "    # MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=audio_array, sr=self.config.sample_rate, n_mfcc=13)\n",
    "    for i in range(mfccs.shape[0]):\n",
    "        features.extend([np.mean(mfccs[i]), np.std(mfccs[i])])\n",
    "    \n",
    "    # Pad or truncate to XVECTOR_DIM\n",
    "    features = np.array(features)\n",
    "    if len(features) < XVECTOR_DIM:\n",
    "        # Pad with zeros\n",
    "        features = np.pad(features, (0, XVECTOR_DIM - len(features)))\n",
    "    else:\n",
    "        # Truncate\n",
    "        features = features[:XVECTOR_DIM]\n",
    "    \n",
    "    return features.astype(np.float32)\n",
    "\n",
    "# Add method to class\n",
    "HaitianCreoleTTSTrainer.extract_xvector = extract_xvector\n",
    "print(\"X-vector extraction method added!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "preprocessing"
   },
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "preprocessing_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing methods added!\n"
     ]
    }
   ],
   "source": [
    "def preprocess_dataset(self) -> None:\n",
    "    \"\"\"Preprocess the entire dataset\"\"\"\n",
    "    logger.info(\"Starting dataset preprocessing...\")\n",
    "    \n",
    "    def preprocess_example(example):\n",
    "        \"\"\"Preprocess a single example\"\"\"\n",
    "        try:\n",
    "            # Extract audio and text\n",
    "            audio_data = example[\"audio\"]\n",
    "            text = example.get(\"text\", \"\")\n",
    "            \n",
    "            # Get audio array and sample rate\n",
    "            audio_array = np.array(audio_data[\"array\"], dtype=np.float32)\n",
    "            orig_sr = audio_data[\"sampling_rate\"]\n",
    "            \n",
    "            # Resample audio\n",
    "            audio_array = self.resample_audio(audio_array, orig_sr)\n",
    "            \n",
    "            # Filter by audio length\n",
    "            audio_duration = len(audio_array) / self.config.sample_rate\n",
    "            \n",
    "            if (audio_duration < self.config.min_audio_length or \n",
    "                audio_duration > self.config.max_audio_length):\n",
    "                return None  # Will be filtered out\n",
    "            \n",
    "            # Normalize text\n",
    "            normalized_text = self.normalize_haitian_text(text)\n",
    "            if not normalized_text:\n",
    "                return None\n",
    "            \n",
    "            # Extract X-vector\n",
    "            xvector = self.extract_xvector(audio_array)\n",
    "            \n",
    "            return {\n",
    "                \"audio\": audio_array,\n",
    "                \"text\": normalized_text,\n",
    "                \"xvector\": xvector,\n",
    "                \"duration\": audio_duration,\n",
    "                \"sample_rate\": self.config.sample_rate,\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error processing example: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    logger.info(\"Applying preprocessing to all examples...\")\n",
    "    processed_examples = []\n",
    "    \n",
    "    for i, example in enumerate(self.dataset):\n",
    "        if i % 100 == 0:\n",
    "            logger.info(f\"Processed {i}/{len(self.dataset)} examples\")\n",
    "        \n",
    "        processed = preprocess_example(example)\n",
    "        if processed is not None:\n",
    "            processed_examples.append(processed)\n",
    "    \n",
    "    logger.info(f\"Preprocessing completed. Kept {len(processed_examples)}/{len(self.dataset)} examples\")\n",
    "    \n",
    "    # Convert back to Dataset\n",
    "    if processed_examples:\n",
    "        self.dataset = Dataset.from_list(processed_examples)\n",
    "    else:\n",
    "        raise ValueError(\"No valid examples after preprocessing\")\n",
    "\n",
    "def split_dataset(self) -> None:\n",
    "    \"\"\"Split dataset into train/validation/test sets\"\"\"\n",
    "    logger.info(\"Splitting dataset...\")\n",
    "    \n",
    "    # First split: 80% train, 20% temp\n",
    "    train_data, temp_data = train_test_split(\n",
    "        list(range(len(self.dataset))), test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Second split: 10% val, 10% test from the 20% temp\n",
    "    val_data, test_data = train_test_split(\n",
    "        temp_data, test_size=0.5, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create dataset splits\n",
    "    self.dataset_splits = DatasetDict({\n",
    "        \"train\": self.dataset.select(train_data),\n",
    "        \"validation\": self.dataset.select(val_data),\n",
    "        \"test\": self.dataset.select(test_data),\n",
    "    })\n",
    "    \n",
    "    logger.info(f\"Dataset split sizes:\")\n",
    "    logger.info(f\"  Train: {len(self.dataset_splits['train'])}\")\n",
    "    logger.info(f\"  Validation: {len(self.dataset_splits['validation'])}\")\n",
    "    logger.info(f\"  Test: {len(self.dataset_splits['test'])}\")\n",
    "\n",
    "def load_models(self) -> None:\n",
    "    \"\"\"Load SpeechT5 processor, model, and vocoder\"\"\"\n",
    "    logger.info(\"Loading SpeechT5 models...\")\n",
    "    \n",
    "    # Load processor\n",
    "    self.processor = SpeechT5Processor.from_pretrained(self.config.model_name)\n",
    "    \n",
    "    # Load model\n",
    "    self.model = SpeechT5ForTextToSpeech.from_pretrained(self.config.model_name)\n",
    "    self.model.to(DEVICE)\n",
    "    \n",
    "    # Load vocoder\n",
    "    self.vocoder = SpeechT5HifiGan.from_pretrained(self.config.vocoder_name)\n",
    "    self.vocoder.to(DEVICE)\n",
    "    \n",
    "    logger.info(\"Models loaded successfully\")\n",
    "\n",
    "# Add methods to class\n",
    "HaitianCreoleTTSTrainer.preprocess_dataset = preprocess_dataset\n",
    "HaitianCreoleTTSTrainer.split_dataset = split_dataset\n",
    "HaitianCreoleTTSTrainer.load_models = load_models\n",
    "print(\"Preprocessing methods added!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "collator"
   },
   "source": [
    "## Data Collator and Custom Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "collator_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collator and custom trainer defined!\n"
     ]
    }
   ],
   "source": [
    "class TTSDataCollator:\n",
    "    \"\"\"Data collator for SpeechT5 TTS training\"\"\"\n",
    "    \n",
    "    def __init__(self, processor: SpeechT5Processor):\n",
    "        self.processor = processor\n",
    "    \n",
    "    def __call__(self, batch: List[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Collate batch for training\"\"\"\n",
    "        # Extract components\n",
    "        texts = [item[\"text\"] for item in batch]\n",
    "        audio_arrays = [item[\"audio\"] for item in batch]\n",
    "        xvectors = [item[\"xvector\"] for item in batch]\n",
    "        \n",
    "        # Process texts to input_ids\n",
    "        text_inputs = self.processor.tokenizer(\n",
    "            texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "        )\n",
    "        \n",
    "        # Process audio to speech features\n",
    "        speech_inputs = self.processor.feature_extractor(\n",
    "            audio_arrays, sampling_rate=config.sample_rate, return_tensors=\"pt\", padding=True\n",
    "        )\n",
    "        \n",
    "        # Stack X-vectors\n",
    "        xvectors_tensor = torch.stack([torch.tensor(xv) for xv in xvectors])\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": text_inputs.input_ids,\n",
    "            \"attention_mask\": text_inputs.attention_mask,\n",
    "            \"labels\": speech_inputs.input_values,\n",
    "            \"speaker_embeddings\": xvectors_tensor,\n",
    "        }\n",
    "\n",
    "\n",
    "class TTSTrainer(Trainer):\n",
    "    \"\"\"Custom trainer for SpeechT5 TTS\"\"\"\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"Compute training loss\"\"\"\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        speaker_embeddings = inputs.pop(\"speaker_embeddings\")\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            labels=labels,\n",
    "            speaker_embeddings=speaker_embeddings,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "    def log_metrics(self, logs: Dict[str, float], step: int) -> None:\n",
    "        \"\"\"Log training metrics to HF Hub and tensorboard\"\"\"\n",
    "        super().log(logs)\n",
    "        \n",
    "        # Log to HF Hub (if available)\n",
    "        if hasattr(self.model, 'hf_api') and self.model.hf_api is not None:\n",
    "            try:\n",
    "                # Create metrics file for this step\n",
    "                metrics_data = {\n",
    "                    \"step\": step,\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    **logs\n",
    "                }\n",
    "                \n",
    "                import json\n",
    "                metrics_file = f\"metrics_step_{step}.json\"\n",
    "                with open(metrics_file, 'w') as f:\n",
    "                    json.dump(metrics_data, f, indent=2)\n",
    "                \n",
    "                # Upload to HF Hub\n",
    "                self.model.hf_api.upload_file(\n",
    "                    path_or_fileobj=metrics_file,\n",
    "                    path_in_repo=f\"training_logs/{metrics_file}\",\n",
    "                    repo_id=self.model.hf_repo_id,\n",
    "                    commit_message=f\"Add training metrics for step {step}\"\n",
    "                )\n",
    "                \n",
    "                # Clean up local file\n",
    "                import os\n",
    "                os.remove(metrics_file)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to log metrics to HF Hub: {e}\")\n",
    "\n",
    "print(\"Data collator and custom trainer defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "initialize"
   },
   "source": [
    "## Initialize Trainer and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "initialize_code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initialized HF Hub repo: haitian-creole-tts-microsoft-speecht5_tts\n",
      "INFO:__main__:Loading dataset: EdManZoeTech/edman_haitian_creole_dataset_4_tts\n",
      "ERROR:__main__:Error loading dataset: name 'datasets' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m tts_trainer \u001b[38;5;241m=\u001b[39m HaitianCreoleTTSTrainer(config)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m tts_trainer\u001b[38;5;241m.\u001b[39mload_dataset()\n",
      "Cell \u001b[0;32mIn[33], line 42\u001b[0m, in \u001b[0;36mHaitianCreoleTTSTrainer.load_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m load_dataset(\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdataset_name, \n\u001b[1;32m     41\u001b[0m         split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 42\u001b[0m         features\u001b[38;5;241m=\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mFeatures({\n\u001b[1;32m     43\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m'\u001b[39m: Audio(sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m),\n\u001b[1;32m     44\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: datasets\u001b[38;5;241m.\u001b[39mValue(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m         })\n\u001b[1;32m     46\u001b[0m     )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Fallback: load without automatic audio decoding\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchcodec not available, loading dataset without automatic audio decoding\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the trainer\n",
    "tts_trainer = HaitianCreoleTTSTrainer(config)\n",
    "\n",
    "# Load dataset\n",
    "tts_trainer.load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "preprocess"
   },
   "source": [
    "## Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "preprocess_code"
   },
   "outputs": [],
   "source": [
    "# Preprocess dataset\n",
    "tts_trainer.preprocess_dataset()\n",
    "\n",
    "# Split dataset\n",
    "tts_trainer.split_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "load_models"
   },
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_models_code"
   },
   "outputs": [],
   "source": [
    "# Load models\n",
    "tts_trainer.load_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_code"
   },
   "outputs": [],
   "source": [
    "# Setup training\n",
    "data_collator = TTSDataCollator(tts_trainer.processor)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=config.output_dir,\n",
    "    num_train_epochs=config.num_train_epochs,\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "    warmup_steps=config.warmup_steps,\n",
    "    learning_rate=config.learning_rate,\n",
    "    weight_decay=config.weight_decay,\n",
    "    logging_steps=config.logging_steps,\n",
    "    eval_steps=config.eval_steps,\n",
    "    save_steps=config.save_steps,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=config.fp16,\n",
    "    dataloader_num_workers=config.dataloader_num_workers,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    report_to=[\"tensorboard\"] if TENSORBOARD_AVAILABLE else None,\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = TTSTrainer(\n",
    "    model=tts_trainer.model,\n",
    "    args=training_args,\n",
    "    train_dataset=tts_trainer.dataset_splits[\"train\"],\n",
    "    eval_dataset=tts_trainer.dataset_splits[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tts_trainer.processor.tokenizer,\n",
    ")\n",
    "\n",
    "print(\"Training setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train"
   },
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_code"
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "logger.info(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Save final model\n",
    "logger.info(\"Saving final model...\")\n",
    "trainer.save_model()\n",
    "tts_trainer.processor.save_pretrained(config.output_dir)\n",
    "\n",
    "print(\"Training completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference"
   },
   "source": [
    "## Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inference_code"
   },
   "outputs": [],
   "source": [
    "def test_haitian_tts(tts_trainer: HaitianCreoleTTSTrainer, config: TTSConfig):\n",
    "    \"\"\"Test the fine-tuned model with sample Haitian Creole text\"\"\"\n",
    "    \n",
    "    # Sample Haitian Creole texts\n",
    "    test_texts = [\n",
    "        \"Bonjou, kijan ou ye?\",  # Hello, how are you?\n",
    "        \"Mwen renmen pale kreyol ayisyen.\",  # I like to speak Haitian Creole\n",
    "        \"Nou ap aprann teknoloji nouvo yo.\",  # We are learning new technologies\n",
    "    ]\n",
    "    \n",
    "    logger.info(\"Testing with sample Haitian Creole texts...\")\n",
    "    \n",
    "    for i, text in enumerate(test_texts):\n",
    "        logger.info(f\"Generating speech for: '{text}'\")\n",
    "        \n",
    "        # Normalize text\n",
    "        normalized_text = tts_trainer.normalize_haitian_text(text)\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = tts_trainer.processor.tokenizer(\n",
    "            normalized_text, return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        # Use a sample X-vector from test set\n",
    "        if len(tts_trainer.dataset_splits[\"test\"]) > 0:\n",
    "            sample_xvector = (\n",
    "                torch.tensor(tts_trainer.dataset_splits[\"test\"][0][\"xvector\"])\n",
    "                .unsqueeze(0)\n",
    "                .to(DEVICE)\n",
    "            )\n",
    "        else:\n",
    "            # Create a dummy X-vector if no test data\n",
    "            sample_xvector = torch.randn(1, XVECTOR_DIM).to(DEVICE)\n",
    "        \n",
    "        # Generate speech\n",
    "        with torch.no_grad():\n",
    "            tts_trainer.model.eval()\n",
    "            speech = tts_trainer.model.generate_speech(\n",
    "                inputs.input_ids,\n",
    "                speaker_embeddings=sample_xvector,\n",
    "                vocoder=tts_trainer.vocoder,\n",
    "            )\n",
    "        \n",
    "        # Save generated audio\n",
    "        output_path = f\"{config.output_dir}/generated_sample_{i+1}.wav\"\n",
    "        torchaudio.save(output_path, speech.cpu().unsqueeze(0), config.sample_rate)\n",
    "        \n",
    "        logger.info(f\"Generated audio saved to: {output_path}\")\n",
    "        \n",
    "        # Display audio in Colab\n",
    "        from IPython.display import Audio, display\n",
    "        display(Audio(output_path))\n",
    "    \n",
    "    logger.info(\"Inference testing completed!\")\n",
    "\n",
    "# Test inference\n",
    "test_haitian_tts(tts_trainer, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "The fine-tuning process is now complete! You should have:\n",
    "\n",
    "1. ✅ Loaded and preprocessed the Haitian Creole TTS dataset\n",
    "2. ✅ Fine-tuned the SpeechT5 model for Haitian Creole\n",
    "3. ✅ Generated sample audio files with Haitian Creole text\n",
    "4. ✅ Saved the trained model for future use\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different training parameters\n",
    "- Try longer training epochs for better quality\n",
    "- Implement proper X-vector extraction for better speaker modeling\n",
    "- Integrate with your applications for Haitian Creole TTS\n",
    "\n",
    "### Model Files:\n",
    "Your trained model is saved in `./haitian_creole_tts_model/` and can be loaded using:\n",
    "```python\n",
    "from transformers import SpeechT5ForTextToSpeech, SpeechT5Processor\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained('./haitian_creole_tts_model')\n",
    "processor = SpeechT5Processor.from_pretrained('./haitian_creole_tts_model')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
